{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from deepymod.data import Dataset\n",
    "from deepymod.data.burgers import BurgersDelta\n",
    "from sklearn.linear_model import BayesianRidge, ARDRegression\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.linalg import pinvh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1) (5000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Making dataset\n",
    "v = 0.1\n",
    "A = 1.0\n",
    "\n",
    "x = np.linspace(-3, 4, 100)\n",
    "t = np.linspace(0.5, 5.0, 50)\n",
    "x_grid, t_grid = np.meshgrid(x, t, indexing='ij')\n",
    "dataset = Dataset(BurgersDelta, v=v, A=A)\n",
    "\n",
    "y = dataset.time_deriv(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1)) # observations\n",
    "X = dataset.library(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1), poly_order=2, deriv_order=3) # covariates\n",
    "\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y += np.std(y) * 0.5 * np.random.randn(*y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08815537241970857"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y) * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBL_loss(X, y, alpha_, beta_, threshold=False):\n",
    "    if isinstance(threshold, float):\n",
    "        mask = alpha_ < threshold\n",
    "    else:\n",
    "        mask = torch.ones_like(alpha_, dtype=torch.bool)\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    X_keep = X[:, mask]\n",
    "    A_inv = torch.inverse(torch.diag(alpha_[mask]) + beta_ * X_keep.T @ X_keep)\n",
    "    mn = torch.zeros((alpha_.shape[0], 1)).to(X.device)\n",
    "    mn[mask, :] = beta_ * A_inv @ X_keep.T @ y\n",
    "    E = beta_ * torch.sum((y - X @ mn)**2) + (alpha_[:, None] * mn**2).sum()\n",
    "\n",
    "    p_reg = E - (torch.logdet(A_inv) + n_samples * torch.log(beta_) + torch.sum(torch.log(alpha_))) # we use alpha and lambda since these are bounded\n",
    "    return p_reg, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-d07ffb631818>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "<ipython-input-22-d07ffb631818>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Now let's optimize\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "X = X / torch.norm(X, dim=0, keepdim=True)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "a = torch.nn.Parameter(torch.zeros(12, dtype=torch.float32))\n",
    "b = torch.nn.Parameter(-torch.log(torch.var(y)))\n",
    "\n",
    "optimizer = torch.optim.Adam([a, b], lr=1e-2)\n",
    "max_epochs=1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-16199.5645, grad_fn=<SubBackward0>)\n",
      "tensor(-20188.8105, grad_fn=<SubBackward0>)\n",
      "tensor(-20190.8887, grad_fn=<SubBackward0>)\n",
      "tensor(-20191.1055, grad_fn=<SubBackward0>)\n",
      "tensor(-20191.1699, grad_fn=<SubBackward0>)\n",
      "tensor(-20191.1973, grad_fn=<SubBackward0>)\n",
      "tensor(-20191.2090, grad_fn=<SubBackward0>)\n",
      "tensor(-20191.2188, grad_fn=<SubBackward0>)\n",
      "tensor(-20191.2207, grad_fn=<SubBackward0>)\n",
      "tensor(-20191.2266, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in torch.arange(max_epochs):\n",
    "    alpha_ = torch.min(torch.exp(a), torch.tensor(1e8, dtype=torch.float32))\n",
    "    beta_ = torch.min(torch.exp(b), torch.tensor(2e4, dtype=torch.float32))\n",
    "    loss = SBL_loss(X, y, alpha_, beta_)[0]\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.8950e-06],\n",
       "        [-2.1367e-05],\n",
       "        [ 7.2259e+00],\n",
       "        [ 9.6952e-08],\n",
       "        [ 3.8401e-05],\n",
       "        [-1.0376e+01],\n",
       "        [ 7.6844e-07],\n",
       "        [ 1.0455e-06],\n",
       "        [ 9.3409e-02],\n",
       "        [-6.6177e-06],\n",
       "        [ 6.0028e-06],\n",
       "        [ 4.2977e-06]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBL_loss(X, y, alpha_, beta_)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.8486e+05],\n",
       "        [6.1259e+04],\n",
       "        [1.9149e-02],\n",
       "        [4.7361e+05],\n",
       "        [1.6055e+05],\n",
       "        [9.2873e-03],\n",
       "        [3.9678e+05],\n",
       "        [7.7817e+05],\n",
       "        [6.8181e+01],\n",
       "        [2.0137e+04],\n",
       "        [4.4681e+05],\n",
       "        [6.5886e+05]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(154.8037, grad_fn=<MinBackward2>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = BayesianRidge(alpha_1=0, alpha_2=0, lambda_1=0, lambda_2=0, fit_intercept=False, compute_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gert-jan/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=0, alpha_2=0, compute_score=True, fit_intercept=False,\n",
       "              lambda_1=0, lambda_2=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0168327 ],\n",
       "       [-0.35016102],\n",
       "       [ 7.59289441],\n",
       "       [ 0.46593763],\n",
       "       [-0.36257924],\n",
       "       [-9.18487524],\n",
       "       [-1.23731263],\n",
       "       [-0.58438872],\n",
       "       [ 0.5934701 ],\n",
       "       [-1.06542042],\n",
       "       [ 1.2996297 ],\n",
       "       [ 0.03825993]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07816731595357417"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.lambda_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BR_loss(X, y, alpha_, beta_):\n",
    "    n_samples = X.shape[0]\n",
    "    alpha = alpha_ * torch.ones(X.shape[1])\n",
    "    \n",
    "    A_inv = torch.inverse(torch.diag(alpha) + beta_ * X.T @ X)\n",
    "    mn = beta_ * A_inv @ X.T @ y\n",
    "    E = beta_ * torch.sum((y - X @ mn)**2) + (alpha[:, None] * mn**2).sum()\n",
    "\n",
    "    p_reg = E - (torch.logdet(A_inv) + n_samples * torch.log(beta_) + torch.sum(torch.log(alpha))) # we use alpha and lambda since these are bounded\n",
    "    return p_reg, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-619bda0ae4e1>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "<ipython-input-43-619bda0ae4e1>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Now let's optimize\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "X = X / torch.norm(X, dim=0, keepdim=True)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "a = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
    "b = torch.nn.Parameter(-torch.log(torch.var(y)))\n",
    "\n",
    "optimizer = torch.optim.Adam([a, b], lr=1e-2)\n",
    "max_epochs=1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-16199.5645, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4570, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4551, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4551, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4570, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4570, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4570, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4570, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4570, grad_fn=<SubBackward0>)\n",
      "tensor(-20138.4570, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in torch.arange(max_epochs):\n",
    "    alpha_ = torch.min(torch.exp(a), torch.tensor(1e8, dtype=torch.float32))\n",
    "    beta_ = torch.min(torch.exp(b), torch.tensor(2e4, dtype=torch.float32))\n",
    "    loss = BR_loss(X, y, alpha_, beta_)[0]\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0782], grad_fn=<MinBackward2>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0169],\n",
       "        [-0.3498],\n",
       "        [ 7.5921],\n",
       "        [ 0.4656],\n",
       "        [-0.3633],\n",
       "        [-9.1862],\n",
       "        [-1.2336],\n",
       "        [-0.5853],\n",
       "        [ 0.5948],\n",
       "        [-1.0653],\n",
       "        [ 1.2974],\n",
       "        [ 0.0392]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BR_loss(X, y, alpha_, beta_)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(154.6533, grad_fn=<MinBackward2>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems the same, great :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
