{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from deepymod.data import Dataset\n",
    "from deepymod.data.burgers import BurgersDelta\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1) (5000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Making dataset\n",
    "v = 0.1\n",
    "A = 1.0\n",
    "\n",
    "x = np.linspace(-3, 4, 100)\n",
    "t = np.linspace(0.5, 5.0, 50)\n",
    "x_grid, t_grid = np.meshgrid(x, t, indexing='ij')\n",
    "dataset = Dataset(BurgersDelta, v=v, A=A)\n",
    "\n",
    "y = dataset.time_deriv(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1)) # observations\n",
    "X = dataset.library(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1), poly_order=2, deriv_order=3) # covariates\n",
    "\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y += np.std(y) * 0.5 * np.random.randn(*y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08933559145075419"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / np.linalg.norm(X, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = BayesianRidge(alpha_1=0, alpha_2=0, lambda_1=0, lambda_2=0, fit_intercept=False, compute_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gert-jan/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=0, alpha_2=0, compute_score=True, fit_intercept=False,\n",
       "              lambda_1=0, lambda_2=0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15504377],\n",
       "       [-0.63589557],\n",
       "       [ 7.04794524],\n",
       "       [-0.17541755],\n",
       "       [ 0.42338914],\n",
       "       [-9.49679341],\n",
       "       [-0.10483916],\n",
       "       [ 0.83393106],\n",
       "       [-0.5301025 ],\n",
       "       [-0.36535585],\n",
       "       [ 0.06563282],\n",
       "       [-0.65920726]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08105813835726926"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08071557742563541"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1 / reg.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3449.51615418, 5455.4724688 , 5455.93969817, 5455.94012097,\n",
       "       5455.94012156, 5455.94012841])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent through pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_ridge(X, y, alpha_, beta_):\n",
    "    n_samples = X.shape[0]\n",
    "    alpha = alpha_ * torch.ones(X.shape[1])\n",
    "    \n",
    "    A_inv = torch.inverse(torch.diag(alpha) + beta_ * X.T @ X)\n",
    "    mn = beta_ * A_inv @ X.T @ y\n",
    "    E = beta_ * torch.sum((y - X @ mn)**2) + (alpha[:, None] * mn**2).sum()\n",
    "    \n",
    "    p_reg = E - (torch.logdet(A_inv) + n_samples * torch.log(beta_) + torch.sum(torch.log(alpha))) # we use alpha and lambda since these are bounded\n",
    "    return p_reg, mn, A_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's optimize\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "a = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
    "b = torch.nn.Parameter(-torch.log(torch.var(y)))\n",
    "\n",
    "optimizer = torch.optim.Adam([a, b], lr=1e-2)\n",
    "max_epochs=1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-16068.9326, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4160, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4141, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4160, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4160, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4160, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4160, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4160, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4160, grad_fn=<SubBackward0>)\n",
      "tensor(-20114.4160, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in torch.arange(max_epochs):\n",
    "    alpha_ = torch.exp(a).clamp(max=1e8)\n",
    "    beta_ = torch.exp(b).clamp(max=1e8)\n",
    "    loss = bayesian_ridge(X, y, alpha_, beta_)[0]\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(153.8698, grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0875], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1726],\n",
       "        [-0.6785],\n",
       "        [ 7.0208],\n",
       "        [-0.3478],\n",
       "        [-0.5703],\n",
       "        [-8.7699],\n",
       "        [ 0.2836],\n",
       "        [ 0.8696],\n",
       "        [ 0.6079],\n",
       "        [-1.5007],\n",
       "        [ 0.3572],\n",
       "        [-0.7488]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge(X, y, alpha_, beta_)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the same :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 ms, sys: 193 µs, total: 11 ms\n",
      "Wall time: 933 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(-20114.4160, grad_fn=<SubBackward0>),\n",
       " tensor([[ 0.1726],\n",
       "         [-0.6785],\n",
       "         [ 7.0208],\n",
       "         [-0.3478],\n",
       "         [-0.5703],\n",
       "         [-8.7699],\n",
       "         [ 0.2836],\n",
       "         [ 0.8696],\n",
       "         [ 0.6079],\n",
       "         [-1.5007],\n",
       "         [ 0.3572],\n",
       "         [-0.7488]], grad_fn=<MmBackward>),\n",
       " tensor([[ 1.4191e-02, -4.2949e-03, -1.5426e-02, -6.1098e-03, -2.4818e-02,\n",
       "           6.8010e-03,  4.4833e-02,  1.7033e-03,  2.4154e-02, -1.0244e-02,\n",
       "          -2.2387e-02,  1.1025e-03],\n",
       "         [-4.2948e-03,  1.2603e-01,  1.2305e-02, -2.1856e-02, -1.1560e-03,\n",
       "          -2.8206e-01,  6.3731e-02, -4.9729e-02,  1.4844e-02,  1.6781e-01,\n",
       "          -7.0673e-02,  6.5450e-02],\n",
       "         [-1.5426e-02,  1.2305e-02,  1.6215e-01,  1.1285e-01,  2.3621e-02,\n",
       "           4.9910e-02, -4.8065e-01, -9.1944e-02, -5.3215e-02, -2.4892e-02,\n",
       "           3.1999e-01, -5.9870e-04],\n",
       "         [-6.1100e-03, -2.1856e-02,  1.1285e-01,  1.7461e-01,  9.9012e-03,\n",
       "           1.0605e-01, -3.4136e-01, -2.3736e-01, -3.5808e-02, -5.9979e-02,\n",
       "           2.2473e-01,  9.3131e-02],\n",
       "         [-2.4818e-02, -1.1553e-03,  2.3621e-02,  9.9006e-03,  1.5120e-01,\n",
       "          -3.5006e-02, -1.4042e-01,  2.3211e-02, -1.9039e-01,  9.5597e-02,\n",
       "           2.2733e-02, -2.0323e-03],\n",
       "         [ 6.8007e-03, -2.8206e-01,  4.9911e-02,  1.0605e-01, -3.5005e-02,\n",
       "           7.9349e-01, -3.6413e-01,  1.3495e-01,  1.2213e-02, -5.4719e-01,\n",
       "           3.6583e-01, -2.4024e-01],\n",
       "         [ 4.4834e-02,  6.3730e-02, -4.8065e-01, -3.4135e-01, -1.4042e-01,\n",
       "          -3.6413e-01,  1.7664e+00,  1.0433e-01,  2.9724e-01,  1.4660e-01,\n",
       "          -1.2122e+00,  1.5852e-01],\n",
       "         [ 1.7034e-03, -4.9729e-02, -9.1946e-02, -2.3736e-01,  2.3211e-02,\n",
       "           1.3495e-01,  1.0433e-01,  6.4539e-01, -3.1739e-02, -8.0823e-02,\n",
       "          -1.8490e-02, -4.3705e-01],\n",
       "         [ 2.4154e-02,  1.4843e-02, -5.3215e-02, -3.5807e-02, -1.9039e-01,\n",
       "           1.2215e-02,  2.9724e-01, -3.1740e-02,  2.7411e-01, -1.2488e-01,\n",
       "          -9.7675e-02,  1.2976e-02],\n",
       "         [-1.0244e-02,  1.6781e-01, -2.4892e-02, -5.9980e-02,  9.5595e-02,\n",
       "          -5.4719e-01,  1.4660e-01, -8.0823e-02, -1.2488e-01,  4.6936e-01,\n",
       "          -2.4793e-01,  1.8744e-01],\n",
       "         [-2.2387e-02, -7.0673e-02,  3.1999e-01,  2.2472e-01,  2.2734e-02,\n",
       "           3.6583e-01, -1.2122e+00, -1.8487e-02, -9.7676e-02, -2.4792e-01,\n",
       "           9.3008e-01, -1.9544e-01],\n",
       "         [ 1.1025e-03,  6.5450e-02, -5.9811e-04,  9.3131e-02, -2.0324e-03,\n",
       "          -2.4024e-01,  1.5852e-01, -4.3705e-01,  1.2976e-02,  1.8744e-01,\n",
       "          -1.9544e-01,  3.8165e-01]], grad_fn=<InverseBackward>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bayesian_ridge(X, y, alpha_, beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3440.17045922, 5462.18384077, 5462.51501708, 5462.51507218,\n",
       "       5462.5150722 , 5462.51507272])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct of marginalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "M = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 400 ms, total: 18.5 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C = beta_**-1 * torch.eye(N) + alpha_**-1 * X @ X.T\n",
    "p =-1/2 * (N * np.log(2*np.pi) + torch.logdet(C) + y.T @ torch.inverse(C) @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5462.3301]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 389 ms, total: 18.5 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C = beta_**-1 * torch.eye(N) + alpha_**-1 * X @ X.T\n",
    "p = torch.logdet(C) + y.T @ torch.inverse(C) @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-20114.0469]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets use woodbury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'M' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "C_inv = beta_ * (torch.eye(N) - X @ torch.inverse(alpha / beta_ + X.T @ X) @ X.T)\n",
    "\n",
    "p = - torch.logdet(C_inv) + y.T @ C_inv @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-20114.4570]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 ms, sys: 183 µs, total: 10.6 ms\n",
      "Wall time: 1.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Optimized version\n",
    "alpha = alpha_ * torch.eye(M)\n",
    "gram = X.T @ X\n",
    "sigma = torch.inverse(alpha / beta_ + gram)\n",
    "log_det_C_inv = torch.logdet(torch.eye(M) -  gram @ sigma)\n",
    "p = - N * torch.log(beta_) - log_det_C_inv + beta_ * (y.T @ y - y.T @ X @ sigma @ X.T @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_ridge_direct(X, y, alpha_, beta_):\n",
    "    N, M = X.shape[0], X.shape[1]\n",
    "    \n",
    "    gram = X.T @ X\n",
    "    sigma = torch.inverse((alpha_ / beta_) * torch.eye(M) + gram)\n",
    "    mn = sigma @ X.T @ y\n",
    "    \n",
    "    p = - N * torch.log(beta_) - torch.logdet(torch.eye(M) -  gram @ sigma) + beta_ * (y.T @ y - y.T @ X @ mn)\n",
    "    return p, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 ms, sys: 0 ns, total: 11.8 ms\n",
      "Wall time: 969 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-20081.8301]], grad_fn=<AddBackward0>),\n",
       " tensor([[-0.0169],\n",
       "         [-0.3715],\n",
       "         [ 7.0453],\n",
       "         [ 0.0754],\n",
       "         [-0.4383],\n",
       "         [-8.9243],\n",
       "         [ 0.3066],\n",
       "         [ 0.3772],\n",
       "         [ 0.6063],\n",
       "         [-1.5424],\n",
       "         [ 0.3798],\n",
       "         [-0.6396]], grad_fn=<MmBackward>))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bayesian_ridge_direct(X, y, alpha_, beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-104-37c047237d63>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "<ipython-input-104-37c047237d63>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Now let's optimize\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "a = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
    "b = torch.nn.Parameter(-torch.log(torch.var(y)))\n",
    "\n",
    "optimizer = torch.optim.Adam([a, b], lr=1e-2)\n",
    "max_epochs=1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-16122.0713]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.6934]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.6523]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.6973]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.4922]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.6133]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.6016]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.8086]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.7441]], grad_fn=<AddBackward0>)\n",
      "tensor([[-20081.7324]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-de0361bc6b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0malpha_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbeta_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesian_ridge_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-ed4d938728fe>\u001b[0m in \u001b[0;36mbayesian_ridge_direct\u001b[0;34m(X, y, alpha_, beta_)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlog_det_C_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m  \u001b[0mgram\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_det_C_inv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in torch.arange(max_epochs):\n",
    "    alpha_ = torch.exp(a).clamp(max=1e8)\n",
    "    beta_ = torch.exp(b).clamp(max=1e8)\n",
    "    loss = bayesian_ridge_direct(X, y, alpha_, beta_)[0]\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0880], grad_fn=<ClampBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(152.8511, grad_fn=<ClampBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
